{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "370a2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\a-rao\\Amphion\n",
      "Python path includes project root: True\n",
      "‚úì All imports successful\n",
      "Using device: cpu\n",
      "‚úì Config loaded\n"
     ]
    }
   ],
   "source": [
    "# Setup and Imports\n",
    "# NOTE: If kernel died, restart it (Kernel ‚Üí Restart Kernel) and run all cells from the beginning\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# CRITICAL: Add project root to path BEFORE importing project modules\n",
    "# Try relative path first, fallback to absolute\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\", \"..\"))\n",
    "    if not os.path.exists(os.path.join(project_root, \"utils\", \"util.py\")):\n",
    "        raise FileNotFoundError\n",
    "except:\n",
    "    # Fallback to absolute path\n",
    "    project_root = r\"C:\\Users\\a-rao\\Amphion\"\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Verify path is set\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python path includes project root: {project_root in sys.path}\")\n",
    "\n",
    "# Now import standard libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import shutil\n",
    "import gc\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Now import project modules (after path is set)\n",
    "try:\n",
    "    from utils.util import load_config\n",
    "    from models.tts.metis.audio_tokenizer import AudioTokenizer\n",
    "    from models.tts.metis.semantic_8d_wrappers import Metis8dEncoder, Metis8dDecoder\n",
    "    print(\"‚úì All imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(f\"Current sys.path: {sys.path[:3]}...\")\n",
    "    print(f\"Looking for utils in: {os.path.join(project_root, 'utils')}\")\n",
    "    raise\n",
    "\n",
    "# Memory management helper\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU and CPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "# Directories\n",
    "test_audios_dir = os.path.join(project_root, \"models\", \"tts\", \"metis\", \"test audios\")\n",
    "result_audios_dir = os.path.join(project_root, \"models\", \"tts\", \"metis\", \"result audios\")\n",
    "os.makedirs(test_audios_dir, exist_ok=True)\n",
    "os.makedirs(result_audios_dir, exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load config\n",
    "cfg_path = os.path.join(project_root, \"models\", \"tts\", \"metis\", \"config\", \"base.json\")\n",
    "cfg = load_config(cfg_path)\n",
    "print(\"‚úì Config loaded\")\n",
    "clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77b0141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING MODELS\n",
      "======================================================================\n",
      "\n",
      "1. Loading AudioTokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822fc13be245495da184048f2d2f61c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4a628b581b4c19877a79936b695a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/177M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bd22b9005b497a9a248ef1f939cebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793f55fb62b64d6697f1e0853692ac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/170M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a583f15a83045aa85ba007240057258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd4f9382e3c4ac8b3dd9af78f16eb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_1.safetensors:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì AudioTokenizer initialized\n",
      "\n",
      "2. Loading Metis8dEncoder...\n",
      "   ‚úì Metis8dEncoder initialized\n",
      "\n",
      "3. Loading Metis8dDecoder (this may take a few minutes)...\n",
      "Building S2A models...\n",
      "Downloading S2A model checkpoints (this may take 5-10 minutes)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e02f40aedf64a68a9c2ad4737297fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e7e3355c1e49aaaa9551dbf5079ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Downloaded s2a_model_1layer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733006ae5bed4045ada18b7a8bd65a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3672fb628a494edf83ebe3272ed6cdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Downloaded s2a_model_full\n",
      "   ‚úì Metis8dDecoder initialized\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL MODELS LOADED\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Models\n",
    "print(\"=\" * 70)\n",
    "print(\"INITIALIZING MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. Loading AudioTokenizer...\")\n",
    "audio_tokenizer = AudioTokenizer(cfg, device)\n",
    "print(\"   ‚úì AudioTokenizer initialized\")\n",
    "clear_memory()\n",
    "\n",
    "print(\"\\n2. Loading Metis8dEncoder...\")\n",
    "encoder = Metis8dEncoder(audio_tokenizer)\n",
    "print(\"   ‚úì Metis8dEncoder initialized\")\n",
    "clear_memory()\n",
    "\n",
    "print(\"\\n3. Loading Metis8dDecoder (this may take a few minutes)...\")\n",
    "decoder = Metis8dDecoder(cfg, audio_tokenizer)\n",
    "print(\"   ‚úì Metis8dDecoder initialized\")\n",
    "clear_memory()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL MODELS LOADED\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61880be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TEST 1: BASIC RECONSTRUCTION\n",
      "Voice ‚Üí 8-D Latents ‚Üí Semantic Codes ‚Üí Waveform\n",
      "======================================================================\n",
      "\n",
      "üìÅ Input: prompt.wav\n",
      "\n",
      "[STEP 1] Encoding audio to 8-D latents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a-rao\\Amphion\\models\\tts\\metis\\semantic_8d_wrappers.py:103: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return self.encode_waveform_16k(librosa.load(wav_path, sr=16000, mono=True)[0])\n",
      "c:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\a-rao\\\\Amphion\\\\models\\\\tts\\\\metis\\\\test audios\\\\prompt.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLibsndfileError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     context = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\soundfile.py:1265\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1264\u001b[39m     err = _snd.sf_error(file_ptr)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix=\u001b[33m\"\u001b[39m\u001b[33mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.name))\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode_int == _snd.SFM_WRITE:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[31mLibsndfileError\u001b[39m: Error opening 'c:\\\\Users\\\\a-rao\\\\Amphion\\\\models\\\\tts\\\\metis\\\\test audios\\\\prompt.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Step 1: Encode to 8-D latents\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[STEP 1] Encoding audio to 8-D latents...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m feat_1024d, z_8d = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_audio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚úì feat_1024d shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeat_1024d.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (1024-D SSL features)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   ‚úì z_8d shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz_8d.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (8-D continuous latents)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\models\\tts\\metis\\semantic_8d_wrappers.py:103\u001b[39m, in \u001b[36mMetis8dEncoder.encode_from_path\u001b[39m\u001b[34m(self, wav_path)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;129m@torch\u001b[39m.no_grad()\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_from_path\u001b[39m(\u001b[38;5;28mself\u001b[39m, wav_path: \u001b[38;5;28mstr\u001b[39m) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load .wav file and encode to (1024-D features, 8-D latents)\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_waveform_16k(\u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n\u001b[32m    181\u001b[39m     warnings.warn(\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[33m\"\u001b[39m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     y, sr_native = \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\util\\decorators.py:63\u001b[39m, in \u001b[36mdeprecated.<locals>.__wrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m warnings.warn(\n\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[39m, in \u001b[36m__audioread_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    237\u001b[39m     reader = path\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     reader = \u001b[43maudioread\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[32m    243\u001b[39m     sr_native = input_file.samplerate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\audioread\\__init__.py:126\u001b[39m, in \u001b[36maudio_open\u001b[39m\u001b[34m(path, backends)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[32m    128\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\a-rao\\Amphion\\.venv\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[39m, in \u001b[36mRawAudioFile.__init__\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28mself\u001b[39m._fh = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mself\u001b[39m._file = aifc.open(\u001b[38;5;28mself\u001b[39m._fh)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\a-rao\\\\Amphion\\\\models\\\\tts\\\\metis\\\\test audios\\\\prompt.wav'"
     ]
    }
   ],
   "source": [
    "# TEST 1: Basic Reconstruction\n",
    "# Voice ‚Üí 8-D Latents ‚Üí Semantic Codes ‚Üí Reconstruction\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 1: BASIC RECONSTRUCTION\")\n",
    "print(\"Voice ‚Üí 8-D Latents ‚Üí Semantic Codes ‚Üí Waveform\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Input audio\n",
    "test_audio = os.path.join(test_audios_dir, \"prompt.wav\")\n",
    "print(f\"\\nüìÅ Input: {os.path.basename(test_audio)}\")\n",
    "\n",
    "# Step 1: Encode to 8-D latents\n",
    "print(\"\\n[STEP 1] Encoding audio to 8-D latents...\")\n",
    "feat_1024d, z_8d = encoder.encode_from_path(test_audio)\n",
    "print(f\"   ‚úì feat_1024d shape: {feat_1024d.shape} (1024-D SSL features)\")\n",
    "print(f\"   ‚úì z_8d shape: {z_8d.shape} (8-D continuous latents)\")\n",
    "print(f\"   ‚úì z_8d dtype: {z_8d.dtype}\")\n",
    "print(f\"   ‚úì z_8d range: [{z_8d.min().item():.4f}, {z_8d.max().item():.4f}]\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 2: 8-D latents ‚Üí Semantic codes\n",
    "print(\"\\n[STEP 2] Quantizing 8-D latents to semantic codes...\")\n",
    "semantic_code = decoder._latent8d_to_semantic_ids(z_8d)\n",
    "print(f\"   ‚úì semantic_code shape: {semantic_code.shape} (discrete token IDs)\")\n",
    "print(f\"   ‚úì semantic_code dtype: {semantic_code.dtype}\")\n",
    "print(f\"   ‚úì semantic_code range: [{semantic_code.min().item()}, {semantic_code.max().item()}] (0-8191)\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 3: Semantic codes ‚Üí Acoustic codes ‚Üí Waveform\n",
    "print(\"\\n[STEP 3] Converting semantic codes to acoustic codes...\")\n",
    "acoustic_code = decoder._semantic2acoustic(semantic_code, prompt_acoustic_code=None)\n",
    "print(f\"   ‚úì acoustic_code shape: {acoustic_code.shape} (12 quantizers)\")\n",
    "print(f\"   ‚úì acoustic_code dtype: {acoustic_code.dtype}\")\n",
    "print(f\"   ‚úì acoustic_code range: [{acoustic_code.min().item()}, {acoustic_code.max().item()}]\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 4: Acoustic codes ‚Üí Waveform\n",
    "print(\"\\n[STEP 4] Decoding acoustic codes to waveform...\")\n",
    "wav_reconstructed = decoder.audio_tok.code2wav(acoustic_code)\n",
    "print(f\"   ‚úì wav_reconstructed shape: {wav_reconstructed.shape}\")\n",
    "print(f\"   ‚úì wav_reconstructed dtype: {wav_reconstructed.dtype}\")\n",
    "print(f\"   ‚úì wav_reconstructed range: [{wav_reconstructed.min():.4f}, {wav_reconstructed.max():.4f}]\")\n",
    "print(f\"   ‚úì Sample rate: 24000 Hz\")\n",
    "print(f\"   ‚úì Duration: {len(wav_reconstructed) / 24000:.2f} seconds\")\n",
    "\n",
    "# Save result\n",
    "output_path = os.path.join(result_audios_dir, \"test1_basic_reconstruction.wav\")\n",
    "sf.write(output_path, wav_reconstructed, 24000)\n",
    "print(f\"\\nüíæ Saved: {os.path.basename(output_path)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TEST 1 COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f36b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2: Voice Conversion with Acoustic Prompt\n",
    "# Voice (prompt.wav) ‚Üí 8-D Latents ‚Üí Semantic Codes + Acoustic Prompt (acoustic.wav) ‚Üí Reconstruction\n",
    "print(\"=\" * 70)\n",
    "print(\"TEST 2: VOICE CONVERSION WITH ACOUSTIC PROMPT\")\n",
    "print(\"Voice (prompt.wav) ‚Üí 8-D Latents ‚Üí Semantic Codes\")\n",
    "print(\"+ Acoustic Prompt (acoustic.wav) ‚Üí Reconstruction\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Input files\n",
    "prompt_audio = os.path.join(test_audios_dir, \"prompt.wav\")\n",
    "acoustic_audio = os.path.join(test_audios_dir, \"acoustic.wav\")\n",
    "print(f\"\\nüìÅ Source voice (content): {os.path.basename(prompt_audio)}\")\n",
    "print(f\"üìÅ Reference voice (style): {os.path.basename(acoustic_audio)}\")\n",
    "\n",
    "# Step 1: Encode source voice to 8-D latents\n",
    "print(\"\\n[STEP 1] Encoding source voice to 8-D latents...\")\n",
    "feat_1024d_source, z_8d_source = encoder.encode_from_path(prompt_audio)\n",
    "print(f\"   ‚úì feat_1024d_source shape: {feat_1024d_source.shape}\")\n",
    "print(f\"   ‚úì z_8d_source shape: {z_8d_source.shape} (8-D continuous latents)\")\n",
    "print(f\"   ‚úì z_8d_source dtype: {z_8d_source.dtype}\")\n",
    "print(f\"   ‚úì z_8d_source range: [{z_8d_source.min().item():.4f}, {z_8d_source.max().item():.4f}]\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 2: Extract acoustic codes from reference voice\n",
    "print(\"\\n[STEP 2] Extracting acoustic codes from reference voice...\")\n",
    "prompt_acoustic_code = encoder.encode_acoustic_from_path(acoustic_audio)\n",
    "print(f\"   ‚úì prompt_acoustic_code shape: {prompt_acoustic_code.shape} (12 quantizers)\")\n",
    "print(f\"   ‚úì prompt_acoustic_code dtype: {prompt_acoustic_code.dtype}\")\n",
    "print(f\"   ‚úì prompt_acoustic_code range: [{prompt_acoustic_code.min().item()}, {prompt_acoustic_code.max().item()}]\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 3: 8-D latents ‚Üí Semantic codes\n",
    "print(\"\\n[STEP 3] Quantizing 8-D latents to semantic codes...\")\n",
    "semantic_code = decoder._latent8d_to_semantic_ids(z_8d_source)\n",
    "print(f\"   ‚úì semantic_code shape: {semantic_code.shape} (discrete token IDs)\")\n",
    "print(f\"   ‚úì semantic_code dtype: {semantic_code.dtype}\")\n",
    "print(f\"   ‚úì semantic_code range: [{semantic_code.min().item()}, {semantic_code.max().item()}] (0-8191)\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 4: Semantic codes + Acoustic prompt ‚Üí Acoustic codes\n",
    "print(\"\\n[STEP 4] Converting semantic codes to acoustic codes (with acoustic prompt)...\")\n",
    "acoustic_code = decoder._semantic2acoustic(semantic_code, prompt_acoustic_code=prompt_acoustic_code)\n",
    "print(f\"   ‚úì acoustic_code shape: {acoustic_code.shape} (12 quantizers)\")\n",
    "print(f\"   ‚úì acoustic_code dtype: {acoustic_code.dtype}\")\n",
    "print(f\"   ‚úì acoustic_code range: [{acoustic_code.min().item()}, {acoustic_code.max().item()}]\")\n",
    "clear_memory()\n",
    "\n",
    "# Step 5: Acoustic codes ‚Üí Waveform\n",
    "print(\"\\n[STEP 5] Decoding acoustic codes to waveform...\")\n",
    "wav_converted = decoder.audio_tok.code2wav(acoustic_code)\n",
    "print(f\"   ‚úì wav_converted shape: {wav_converted.shape}\")\n",
    "print(f\"   ‚úì wav_converted dtype: {wav_converted.dtype}\")\n",
    "print(f\"   ‚úì wav_converted range: [{wav_converted.min():.4f}, {wav_converted.max():.4f}]\")\n",
    "print(f\"   ‚úì Sample rate: 24000 Hz\")\n",
    "print(f\"   ‚úì Duration: {len(wav_converted) / 24000:.2f} seconds\")\n",
    "\n",
    "# Save results\n",
    "shutil.copy2(prompt_audio, os.path.join(result_audios_dir, \"test2_source_prompt.wav\"))\n",
    "shutil.copy2(acoustic_audio, os.path.join(result_audios_dir, \"test2_reference_acoustic.wav\"))\n",
    "output_path = os.path.join(result_audios_dir, \"test2_voice_converted.wav\")\n",
    "sf.write(output_path, wav_converted, 24000)\n",
    "print(f\"\\nüíæ Saved:\")\n",
    "print(f\"   - Source: test2_source_prompt.wav\")\n",
    "print(f\"   - Reference: test2_reference_acoustic.wav\")\n",
    "print(f\"   - Output: {os.path.basename(output_path)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TEST 2 COMPLETE\")\n",
    "print(\"Expected: Output should have prompt.wav content in acoustic.wav voice\")\n",
    "print(\"=\" * 70)\n",
    "clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b132362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary: Dimension Flow\n",
    "print(\"=\" * 70)\n",
    "print(\"DIMENSION FLOW SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìä TEST 1: Basic Reconstruction\")\n",
    "print(\"   Input audio (24kHz) ‚Üí 16kHz for encoding\")\n",
    "print(\"   ‚Üí feat_1024d: [1, T_ssl, 1024]  (SSL features at ~50Hz)\")\n",
    "print(\"   ‚Üí z_8d: [1, T_ssl, 8]           (8-D continuous latents)\")\n",
    "print(\"   ‚Üí semantic_code: [1, T_ssl]     (discrete IDs 0-8191)\")\n",
    "print(\"   ‚Üí acoustic_code: [1, T_ac, 12]  (12 quantizers)\")\n",
    "print(\"   ‚Üí waveform: [T_wav]             (24kHz samples)\")\n",
    "\n",
    "print(\"\\nüìä TEST 2: Voice Conversion\")\n",
    "print(\"   Source audio ‚Üí z_8d_source: [1, T_ssl, 8]\")\n",
    "print(\"   Reference audio ‚Üí prompt_acoustic_code: [1, T_prompt, 12]\")\n",
    "print(\"   ‚Üí semantic_code: [1, T_ssl]     (from source)\")\n",
    "print(\"   ‚Üí acoustic_code: [1, T_ac, 12]  (with reference prompt)\")\n",
    "print(\"   ‚Üí waveform: [T_wav]             (source content, reference voice)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL TESTS COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de231690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
